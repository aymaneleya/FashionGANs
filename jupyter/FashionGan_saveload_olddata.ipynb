{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionGan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgoAuiSSIRGi",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKFONh4omOdN",
        "colab_type": "text"
      },
      "source": [
        "Connect to the drive and if needed extract the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US-qnkZYjYkr",
        "colab_type": "code",
        "outputId": "07c91f5d-ca61-43b1-f0d7-9ac4153e7a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cd \"/content/drive/My Drive\"gdgdgrrjgr"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drivegdgdgrrjgr'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W-gLX7zJQ-r",
        "colab_type": "code",
        "outputId": "59a52055-b4e8-421f-b63e-b7d3c7aff029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlVVVJVqOesd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #dead loop to get 25GB RAM\n",
        "# d=[]\n",
        "# while(1):\n",
        "#   d.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqoos037AMwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from zipfile import ZipFile\n",
        "# file_name = 'data.zip'\n",
        "\n",
        "# with ZipFile(file_name,'r') as zip:\n",
        "#   zip.extractall()\n",
        "#   print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJFaEhMGkuG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDKGd4ysmcaE",
        "colab_type": "text"
      },
      "source": [
        "Adding the down sample library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbXbLhjTm1FK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_segmented_image_7_s_tilde(batch_size,s_tilde):    \n",
        "    img_no_downsample = s_tilde\n",
        "    #img_no_downsample_copy = copy.deepcopy(img_no_downsample)\n",
        "    #Create a tensor 4D, one dimention for each label [0,3]\n",
        "    img_3_layer_tensor = img_no_downsample[:,0:3,:,:]\n",
        "    # take the mean of the indecies > 2\n",
        "    img_4th_layer_tensor = torch.mean(img_no_downsample[:,4:,:,:], dim=1)\n",
        "    img_4th_layer_tensor = img_4th_layer_tensor.view(batch_size,1,128,128)\n",
        "    img_4_layer_tensor = torch.cat([img_3_layer_tensor, img_4th_layer_tensor], dim = 1)\n",
        "    return img_4_layer_tensor\n",
        "\n",
        "def get_segmented_image_7(seg_img):\n",
        "    img_no_downsample = seg_img\n",
        "    img_no_downsample_copy = copy.deepcopy(img_no_downsample)\n",
        "    #Create a tensor 4D, one dimention for each label [0,3]\n",
        "    img_7_lay_tensor = torch.zeros(7, 128, 128)\n",
        "\n",
        "\n",
        "    for i in range(0,7):\n",
        "        # first set the value when the index != label to a dummy value = 4\n",
        "        img_no_downsample_copy[img_no_downsample_copy != i] = 8\n",
        "        # set the value = 1 when the index = label \n",
        "        img_no_downsample_copy[img_no_downsample_copy == i] = 1\n",
        "        # convert from numpty array to tensor\n",
        "        img_no_downsample_copy = torch.from_numpy(img_no_downsample_copy)\n",
        "        #put the tensor in the corresponding index\n",
        "        img_7_lay_tensor[i, :, :] = img_no_downsample_copy\n",
        "        # reset the img_no_downsample_copy in order to process the second label \n",
        "        img_no_downsample_copy = copy.deepcopy(img_no_downsample)\n",
        "\n",
        "    #replace the dummy value in the tensor with 0\n",
        "    img_7_lay_tensor[img_7_lay_tensor == 8] = 0\n",
        "\n",
        "    # convert the tensot to double instead of unit8 (usigned integer)\n",
        "    img_7_lay_tensor = img_7_lay_tensor.type(torch.DoubleTensor)\n",
        "    img_7_lay_tensor = img_7_lay_tensor.resize(1,7,128,128)\n",
        "\n",
        "    img_7_lay_tensor = img_7_lay_tensor.resize(7,128,128)\n",
        "    img_7_lay_tensor = img_7_lay_tensor.permute(0,2,1)\n",
        "        \n",
        "    return img_7_lay_tensor\n",
        "\n",
        "\n",
        "def get_downsampled_image_4(img):\n",
        "    img_no_downsample = img\n",
        "    img_no_downsample_copy = copy.deepcopy(img_no_downsample)\n",
        "    # L´ : only use the first four lables. if label > 3, set label = 3\n",
        "    img_no_downsample[img_no_downsample > 3] = 3\n",
        "    #Create a tensor 4D, one dimention for each label [0,3]\n",
        "    img_4_lay_tensor = torch.zeros(4, 128, 128)\n",
        "\n",
        "    for i in range(0,4):\n",
        "        # first set the value when the index != label to a dummy value = 4\n",
        "        img_no_downsample_copy[img_no_downsample_copy != i] = 4\n",
        "        # set the value = 1 when the index = label \n",
        "        img_no_downsample_copy[img_no_downsample_copy == i] = 1\n",
        "        # convert from numpty array to tensor\n",
        "        img_no_downsample_copy = torch.from_numpy(img_no_downsample_copy)\n",
        "        #put the tensor in the corresponding index\n",
        "        img_4_lay_tensor[i, :, :] = img_no_downsample_copy\n",
        "        # reset the img_no_downsample_copy in order to process the second label \n",
        "        img_no_downsample_copy = copy.deepcopy(img_no_downsample)\n",
        "\n",
        "    #replace the dummy value in the tensor with 0\n",
        "    img_4_lay_tensor[img_4_lay_tensor == 4] = 0\n",
        "\n",
        "    # convert the tensot to double instead of unit8 (usigned integer)\n",
        "    img_4_lay_tensor = img_4_lay_tensor.type(torch.DoubleTensor)\n",
        "    img_4_lay_tensor = img_4_lay_tensor.resize(1,4,128,128)\n",
        "    #segmented_image = segmented_image.view(1,-1,-1,-1)\n",
        "    # downsampling by 1/8\n",
        "    img_4_lay_tensor = torch.nn.functional.interpolate(img_4_lay_tensor, scale_factor=(0.0625, 0.0625),  mode='bicubic', align_corners=True)\n",
        "\n",
        "    img_4_lay_tensor = img_4_lay_tensor.resize(4,8,8)\n",
        "    img_4_lay_tensor = img_4_lay_tensor.permute(0,2,1)\n",
        "        \n",
        "    return img_4_lay_tensor\n",
        "\n",
        "def get_downsampled_image_4_mS0(batch_size,img):\n",
        "    img_no_downsample = img\n",
        "\n",
        "    img_4_lay_tensor = torch.nn.functional.interpolate(img_no_downsample, scale_factor=(0.0625, 0.0625),  mode='bicubic', align_corners=True)\n",
        "\n",
        "    img_4_lay_tensor = img_4_lay_tensor.resize(batch_size,4,8,8)\n",
        "    #img_4_lay_tensor = img_4_lay_tensor.permute(0,2,1)\n",
        "        \n",
        "    return img_4_lay_tensor\n",
        "\n",
        "\n",
        "def plot_tensor_image(t_img):\n",
        "    for i in range(len(t_img)):\n",
        "        segmented_tensor = t_img[i,:,:].resize(8,8)\n",
        "        plt.imshow(segmented_tensor)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_tensor_seg_image(t_img):\n",
        "    for i in range(len(t_img)):\n",
        "        segmented_tensor = t_img[i,:,:].resize(128,128)\n",
        "        plt.imshow(segmented_tensor)\n",
        "        plt.show()\n",
        "\n",
        "def get_downsampled_batch(batchsize,batch):\n",
        "    batch_np = batch.cpu().data.numpy()\n",
        "    batch_down_sampled = torch.ones(batchsize, 4, 8,8)\n",
        "    for i in range(batchsize):\n",
        "        batch_down_sampled[i]=get_downsampled_image_4(batch_np[i])\n",
        "    return batch_down_sampled\n",
        "\n",
        "def get_segmented_batch(batchsize,batch):\n",
        "    batch_np = batch.cpu().data.numpy()\n",
        "    batch_segmented = torch.ones(batchsize, 7, 128,128)\n",
        "    for i in range(batchsize):\n",
        "        batch_segmented[i]=get_segmented_image_7(batch_np[i])\n",
        "    return batch_segmented\n",
        "\n",
        "def get_segmented_image_1(batch_size,segimg_7):\n",
        "    seg_img_7 = copy.deepcopy(segimg_7)\n",
        "    seg_img_1 = torch.zeros(batch_size,128,128).type(torch.float64)\n",
        "    for i in range(batch_size):\n",
        "        for j in range(7):\n",
        "            seg_img_1[i]=seg_img_1[i]+j*seg_img_7[i][j]\n",
        "    return seg_img_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD2XMbvAm_Vv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA9alNNonMKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "def binary_representaiton(val, n_bits):\n",
        "    binary_str = bin(val)[2:]\n",
        "    while n_bits > len(binary_str):\n",
        "            binary_str = '0'+binary_str\n",
        "    arr =[]\n",
        "    for i in range(len(binary_str)):\n",
        "        arr.append(float(binary_str[i]))\n",
        "    return arr\n",
        "\n",
        "\n",
        "def create_mask_for_skin_tone(segmented_image):\n",
        "    mask = copy.deepcopy(segmented_image)\n",
        "    for i in range(7):\n",
        "        if(2 == i or 6 == i):\n",
        "            mask[i == mask] = 1\n",
        "        else:\n",
        "            mask[i==mask] = 0\n",
        "    return mask\n",
        "\n",
        "def apply_mask(segmented_image,real_image):\n",
        "    mask = create_mask_for_skin_tone(segmented_image)\n",
        "    masked = copy.deepcopy(real_image)\n",
        "    for channel in range(len(real_image)):\n",
        "        masked[channel] = np.multiply(masked[channel],mask)\n",
        "    return masked\n",
        "\n",
        "\n",
        "class FashionData(Dataset):\n",
        "    def __init__(self,X,y,type_of_data):\n",
        "        self.X = X[type_of_data]\n",
        "        self.y = y[type_of_data]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        design_encoding = []\n",
        "        design_encoding.append(float(self.X['gender'][index]))\n",
        "        design_encoding.extend(binary_representaiton(self.X['color'][index],5))\n",
        "        design_encoding.extend(binary_representaiton(self.X['sleeve'][index],3))\n",
        "        design_encoding.extend(binary_representaiton(self.X['cate_new'][index],5))\n",
        "        design_encoding.append(self.X['r'][index])\n",
        "        design_encoding.append(self.X['g'][index])\n",
        "        design_encoding.append(self.X['b'][index])\n",
        "        design_encoding.append(self.X['y'][index])\n",
        "        design_encoding.extend(self.X['encoding'][index])\n",
        "        design_encoding = np.array(design_encoding)\n",
        "\n",
        "        #return (self.X['segmented_image'][index],self.y[index])\n",
        "        return (design_encoding,self.X['down_sampled_images'][index],self.X['segmented_image'][index],self.y[index])        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "\n",
        "\n",
        "# should we normalize the real_images\n",
        "def construct_data(segmented_images,real_images,indeces,language,encoded_values):\n",
        "    X = {}\n",
        "    y = {}\n",
        "\n",
        "    X['train'] = {}\n",
        "    X['train']['gender'] =[]\n",
        "    X['train']['color'] =[]\n",
        "    X['train']['sleeve'] =[]\n",
        "    X['train']['cate_new'] =[]\n",
        "    X['train']['segmented_image'] = []\n",
        "    X['train']['down_sampled_images'] = []\n",
        "    X['train']['description'] = []\n",
        "    X['train']['encoding'] = []\n",
        "    X['train']['codeJ'] = []\n",
        "    X['train']['r'] = []\n",
        "    X['train']['g'] = []\n",
        "    X['train']['b'] = []\n",
        "    X['train']['y'] = []\n",
        "\n",
        "    X['test'] = {}\n",
        "    X['test']['gender'] =[]\n",
        "    X['test']['color'] =[]\n",
        "    X['test']['sleeve'] =[]\n",
        "    X['test']['cate_new'] =[]\n",
        "    X['test']['segmented_image'] = []\n",
        "    X['test']['down_sampled_images'] = []\n",
        "    X['test']['description'] = []\n",
        "    X['test']['encoding'] = []\n",
        "    X['test']['codeJ'] = []\n",
        "    X['test']['r'] = []\n",
        "    X['test']['g'] = []\n",
        "    X['test']['b'] = []\n",
        "    X['test']['y'] = []\n",
        "\n",
        "    y['train'] = []\n",
        "    y['test'] = []\n",
        "\n",
        "    # length_to_iterate_train = len(indeces['train_ind'])\n",
        "    length_to_iterate_train = 10000\n",
        "    # length_to_iterate_test = len(indeces['test_ind'])\n",
        "    length_to_iterate_test = 1000\n",
        "\n",
        "\n",
        "    for i in range(length_to_iterate_train):\n",
        "        idx = indeces['train_ind'][i][0] - 1\n",
        "        X['train']['gender'].append(language['gender_'][idx][0])\n",
        "        X['train']['color'].append(language['color_'][idx][0])\n",
        "        X['train']['sleeve'].append(language['sleeve_'][idx][0])\n",
        "        X['train']['cate_new'].append(language['cate_new'][idx][0])\n",
        "        X['train']['description'].append(str(language['engJ'][idx][0][0]))\n",
        "        X['train']['encoding'].append(encoded_values[idx])\n",
        "        # X['train']['segmented_image'].append(segmented_images[idx])\n",
        "        X['train']['segmented_image'].append(get_segmented_image_7(segmented_images[idx]))  \n",
        "        X['train']['codeJ'].append(str(language['codeJ'][idx][0][0]))\n",
        "        skin_tone = apply_mask(np.reshape(segmented_images[idx],(128,128)),real_images[idx])\n",
        "\n",
        "        r,g,b = np.median(skin_tone[0]), np.median(skin_tone[1]), np.median(skin_tone[2])\n",
        "\n",
        "        X['train']['r'].append(r)\n",
        "        X['train']['g'].append(g)\n",
        "        X['train']['b'].append(b)\n",
        "        X['train']['y'].append(0.2125*r + 0.7154*g +  0.0721*b)\n",
        "        #X['train']['down_sampled_images'].append(get_downsampled_image(segmented_images[idx][0]))\n",
        "        X['train']['down_sampled_images'].append(get_downsampled_image_4(segmented_images[idx]))\n",
        "        y['train'].append(real_images[idx])\n",
        "\n",
        "    for i in range(length_to_iterate_test):\n",
        "        idx = indeces['test_ind'][i][0] - 1\n",
        "        X['test']['gender'].append(language['gender_'][idx][0])\n",
        "        X['test']['color'].append(language['color_'][idx][0])\n",
        "        X['test']['sleeve'].append(language['sleeve_'][idx][0])\n",
        "        X['test']['cate_new'].append(language['cate_new'][idx][0])\n",
        "        X['test']['description'].append(str(language['engJ'][idx][0][0]))\n",
        "        X['test']['encoding'].append(encoded_values[idx])\n",
        "        X['test']['segmented_image'].append(get_segmented_image_7(segmented_images[idx]))  \n",
        "        # X['test']['segmented_image'].append(segmented_images[idx])\n",
        "        X['test']['codeJ'].append(str(language['codeJ'][idx][0][0]))\n",
        "        skin_tone = apply_mask(np.reshape(segmented_images[idx],(128,128)),real_images[idx])\n",
        "\n",
        "        r,g,b = np.median(skin_tone[0]), np.median(skin_tone[1]), np.median(skin_tone[2])\n",
        "\n",
        "        X['test']['r'].append(r)\n",
        "        X['test']['g'].append(g)\n",
        "        X['test']['b'].append(b)\n",
        "        X['test']['y'].append(0.2125*r + 0.7154*g +  0.0721*b)\n",
        "\n",
        "        X['test']['down_sampled_images'].append(get_downsampled_image_4(segmented_images[idx]))\n",
        "\n",
        "        y['test'].append(real_images[idx])\n",
        "    \n",
        "    return (X,y)\n",
        "\n",
        "    \n",
        "def normalize_pictures(real_images):\n",
        "    for image in real_images:\n",
        "        for channel in range(len(image)):\n",
        "            image[channel] = (image[channel] - image[channel].min()) / (image[channel].max()-image[channel].min())\n",
        "    return real_images\n",
        "\n",
        "\n",
        "def load_data():\n",
        "\n",
        "    segmented_images = None\n",
        "    real_images = None\n",
        "    print(\"Check if the serialized data is present\")\n",
        "    # check if the serialized images are present if not create them\n",
        "    if not(os.path.isfile(segmented_images_raw_path) and os.path.isfile(real_images_raw_path)):\n",
        "        print(\"We have to read the h5 file, it will take time\")\n",
        "        with h5py.File(h5_file_path, 'r') as f:   \n",
        "\n",
        "            # Get the data\n",
        "            # Segmentated images 1x 128x 128 values from 0 to 6\n",
        "            segmented_images = list(f['b_'])\n",
        "            # Real images three channels instad of 0-255 values for a pixel we have normalized values between [-1;1]\n",
        "            pickle.dump(segmented_images, open(segmented_images_raw_path, 'wb')) \n",
        "            real_images = list(f['ih'])\n",
        "            #normalize the real images\n",
        "            real_images = normalize_pictures(real_images)\n",
        "            pickle.dump(real_images, open(real_images_raw_path, 'wb')) \n",
        "            print(\"H5 read and data has been serialized\")\n",
        "    if None == segmented_images:\n",
        "        infile = open(segmented_images_raw_path,'rb')\n",
        "        segmented_images = pickle.load(infile)\n",
        "        infile.close()\n",
        "\n",
        "    if None == real_images:\n",
        "        real_images = pickle.load(open(real_images_raw_path,'rb'))\n",
        "    print(\"Images has been loaded successfully\")\n",
        "    print(\"Now reading .mat files\")\n",
        "    # now read language\n",
        "    lang_org = scipy.io.loadmat(language_original_path)\n",
        "\n",
        "    # read the indeces as well\n",
        "    indeces = scipy.io.loadmat(indeces_path)\n",
        "\n",
        "    print(\"Everything is loaded now constructing the dictionaries\")\n",
        "    \n",
        "    encoded_values = np.load(lang_encoding)\n",
        "\n",
        "    (X,y) = construct_data(segmented_images,real_images,indeces,lang_org, encoded_values)\n",
        "    print(\"Data constructed\")\n",
        "    print(\"Pickle the data\")\n",
        "    handle = open(os.path.join(os.path.dirname(__file__),'..','data','data.pkl'),'wb')\n",
        "    pickle.dump((X,y), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    handle.close()\n",
        "    \n",
        "    return (X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCLdtWRFoKec",
        "colab_type": "text"
      },
      "source": [
        "Definition of Gans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0MNT0fWoJJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sizes\n",
        "human_attributes_size = 18\n",
        "encoded_description_size = 100\n",
        "flatten_down_sampled_segmentations_size = 256\n",
        "gausian_noise_size = 100\n",
        "\n",
        "design_encoding = human_attributes_size + encoded_description_size + gausian_noise_size # 218\n",
        "\n",
        "\n",
        "\n",
        "class Generator1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator1,self).__init__()\n",
        "\n",
        "        self.G1_Layer2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=design_encoding,out_channels=1024,kernel_size=4,stride=4,padding=0),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.G1_A = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.G1_LastLayers = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=(128+512),out_channels=256,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=64,out_channels=7,kernel_size=4,stride=2,padding=1),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_design_desc, x_down_sampled_image):\n",
        "        x_design = self.G1_Layer2(x_design_desc)\n",
        "        x_down_sampled = self.G1_A(x_down_sampled_image)\n",
        "        concatenated = torch.cat((x_design,x_down_sampled),1)\n",
        "        return self.G1_LastLayers(concatenated)\n",
        "\n",
        "class Generator2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator2,self).__init__()\n",
        "        self.G2_Layer3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=design_encoding,out_channels=1024,kernel_size=4,stride=4,padding=0),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.G2_LayerC = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=7,out_channels=64,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.G2_Layer6 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=128, kernel_size=4, stride=2, padding=1),            \n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x_design_desc, s_tilde):\n",
        "        l3 = self.G2_Layer3(x_design_desc)\n",
        "        lc = self.G2_LayerC(s_tilde)\n",
        "        concatenated = torch.cat((l3,lc),dim=1)\n",
        "        return self.G2_Layer6(concatenated)\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator1,self).__init__()\n",
        "\n",
        "        self.D1_Layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=7,out_channels=64,kernel_size=4,stride=2,padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.D1_condition = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.D1_concatenation = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=640,out_channels=1024,kernel_size=4,stride=2,padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.D1_LastLayers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1142,out_channels=1024,kernel_size=1,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=1024,out_channels=1,kernel_size=4,stride=4,padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x_segmented_image,x_down_sampled, x_design_encoding):\n",
        "        layer4 = self.D1_Layer1(x_segmented_image)\n",
        "        x_down_sampled = self.D1_condition(x_down_sampled)\n",
        "        \n",
        "        concatenated = torch.cat((layer4,x_down_sampled),1)\n",
        "        layer5 = self.D1_concatenation(concatenated)\n",
        "        d_by_4 = x_design_encoding.repeat(1,16)\n",
        "        d_by_4 = d_by_4.view(layer5.shape[0],x_design_encoding.shape[1],4,4)\n",
        "        input_for_layer6 = torch.cat((layer5,d_by_4),1)\n",
        "        output = self.D1_LastLayers(input_for_layer6)\n",
        "        output = output.view(x_segmented_image.shape[0],1)\n",
        "        return self.sigmoid(output)\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator2,self).__init__()\n",
        "        self.D2_Layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),            \n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2)            \n",
        "        )\n",
        "\n",
        "        self.D2_LayerC = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=7,out_channels=64,kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),            \n",
        "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),            \n",
        "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.D2_Layer5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2)         \n",
        "        )\n",
        "\n",
        "        self.D2_Layer7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1142,out_channels=1024,kernel_size=1, stride=1, padding=0),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.Conv2d(in_channels=1024,out_channels=1,kernel_size=4, stride=4, padding=0),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm2d(1)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, design_encoding, g2_output, s_tilde):\n",
        "        l3 = self.D2_Layer3(g2_output)\n",
        "        lc = self.D2_LayerC(s_tilde)\n",
        "        concatenated = torch.cat((l3,lc),dim=1)\n",
        "        l5 = self.D2_Layer5(concatenated)\n",
        "        d_by_4 = design_encoding.repeat(1,16)\n",
        "        d_by_4 = d_by_4.view(l5.shape[0],design_encoding.shape[1],4,4)\n",
        "        input_for_l7 = torch.cat((l5,d_by_4),1)\n",
        "        l7 = self.D2_Layer7(input_for_l7)\n",
        "        return self.sigmoid(l7)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7sW8uCVorpA",
        "colab_type": "text"
      },
      "source": [
        "Training loop of GAN 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEAcrAV-oyaP",
        "colab_type": "code",
        "outputId": "27f31ab9-27d8-4c7e-c477-16a39fa696c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
        "X, y = None,None\n",
        "\n",
        "loaded_data = None\n",
        "# if os.path.isfile(os.path.join(os.path.dirname(__file__),'..','data','debug_data_10k.pkl')):\n",
        "#     with open(os.path.join(os.path.dirname(__file__),'..','data','debug_data_10k.pkl'),'rb') as handle:\n",
        "\n",
        "if True:\n",
        "    with open(\"/content/drive/My Drive/debug_data_10k.pkl\",'rb') as handle:\n",
        "        print(\"I pickle\")\n",
        "        loaded_data = pickle.load(handle)\n",
        "        X,y = loaded_data[0],loaded_data[1]\n",
        "else:\n",
        "    # X, y = load_data()\n",
        "    print(\"we don't have data in the drive\")\n",
        "training_data = FashionData(X,y,'train')\n",
        "testing_data = FashionData(X,y,'test')\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=batch_size,pin_memory=cuda)\n",
        "test_loader  = DataLoader(testing_data, batch_size=batch_size, pin_memory=cuda)\n",
        "\n",
        "\n",
        "G1 = Generator1()\n",
        "D1 = Discriminator1()\n",
        "if cuda:\n",
        "    G1.cuda()\n",
        "    D1.cuda()\n",
        "\n",
        "loss_seg = torch.nn.NLLLoss()\n",
        "loss = torch.nn.BCELoss()\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "generator_1_optim = torch.optim.Adam(G1.parameters(), 0.0002, betas=(0.5, 0.999))\n",
        "discriminator_1_optim = torch.optim.Adam(D1.parameters(), 0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "\n",
        "discriminator_loss, generator_loss = [], []\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    batch_d_loss, batch_g_loss = [], []\n",
        "    \n",
        "    for i , data in enumerate(train_loader, 0):\n",
        "        \n",
        "        d, mS0, S0, label = data\n",
        "        \n",
        "        true_label = torch.ones(batch_size, 1).to(device)\n",
        "        fake_label = torch.zeros(batch_size, 1).to(device)\n",
        "        \n",
        "        D1.zero_grad()\n",
        "        \n",
        "        #################### Update D #############################\n",
        "        # loss 1. real image + real condition -> 1\n",
        "        x_true_S0 = Variable(S0).to(device,dtype=torch.float)\n",
        "        x_true_mS0 = Variable(mS0).to(device,dtype=torch.float)\n",
        "        x_true_d = Variable(d).to(device,dtype=torch.float)        \n",
        "        output = D1.forward(x_true_S0,x_true_mS0,x_true_d)\n",
        "        \n",
        "        error_true = loss(output, true_label) \n",
        "        error_true.backward()\n",
        "\n",
        "        # loss 2. sampled real image + wrong condition -> 0\n",
        "        # shuffle d     \n",
        "        # shuffle the true d row wise\n",
        "        x_notmatch_d = x_true_d[torch.randperm(x_true_d.size()[0])]\n",
        "        \n",
        "        x_notmatch_d = Variable(x_notmatch_d).to(device)    \n",
        "        output = D1.forward(x_true_S0 ,x_true_mS0,x_notmatch_d)\n",
        "\n",
        "        error_notmatch = loss(output, fake_label) \n",
        "        error_notmatch.backward()\n",
        "\n",
        "        # loss 3. generated fake image + real condition -> 0s\n",
        "        z = torch.randn(batch_size, 100,dtype=torch.float64)\n",
        "        dz = torch.cat([d, z] , dim=1)\n",
        "        dz = dz.view((batch_size,dz.shape[1],1,1))\n",
        "        dz = Variable(dz).to(device,dtype=torch.float)\n",
        "        x_g_mS0 = Variable(mS0).to(device,dtype=torch.float)\n",
        "\n",
        "        S_tilde = G1.forward(dz,x_g_mS0)\n",
        "\n",
        "        x_fake_S = S_tilde\n",
        "        mS_tilde = get_segmented_image_7_s_tilde(batch_size, S_tilde)\n",
        "        x_fake_mS = get_downsampled_image_4_mS0(batch_size, mS_tilde)\n",
        "        x_fake_mS = Variable(x_fake_mS).to(device,dtype=torch.float)\n",
        "        x_fake_d = Variable(d).to(device,dtype=torch.float) \n",
        "        output = D1.forward(x_fake_S.detach(),x_fake_mS.detach(),x_fake_d.detach())\n",
        "        \n",
        "\n",
        "        error_fake = loss(output, fake_label)\n",
        "        error_fake.backward()\n",
        "        discriminator_1_optim.step()\n",
        "\n",
        "            \n",
        "        G1.zero_grad()\n",
        "        \n",
        "        #################### Update G #############################\n",
        "        \n",
        "        \n",
        "        # Step 4. Send fake data through discriminator _again_\n",
        "        #         propagate the error of the generator and\n",
        "        #         update G weights.\n",
        "        output = D1.forward(x_fake_S,x_fake_mS,x_fake_d)\n",
        "        target = Variable(get_segmented_image_1(batch_size,S0)).to(device,dtype=torch.long)\n",
        "        error_D = loss(output, true_label)\n",
        "        error_seg = 50*loss_seg(x_fake_S,target)\n",
        "        error_generator = error_seg + error_D\n",
        "        error_generator.backward()\n",
        "        generator_1_optim.step()\n",
        "        \n",
        "        batch_d_loss.append((error_true + error_fake + error_notmatch).item())\n",
        "        batch_g_loss.append(error_generator.item())\n",
        "\n",
        "    discriminator_loss.append(np.mean(batch_d_loss))\n",
        "    generator_loss.append(np.mean(batch_g_loss))\n",
        "\n",
        "    print('Training epoch %d: discriminator_loss = %.5f, generator_loss = %.5f' % (epoch, discriminator_loss[epoch].item(), generator_loss[epoch].item()))\n",
        "   \n",
        "    # Generate data\n",
        "torch.save(G1.state_dict(), '/content/drive/My Drive/G1.pth')\n",
        "torch.save(D1.state_dict(), '/content/drive/My Drive/D1.pth')\n",
        "with torch.no_grad():\n",
        "    zsample = torch.randn(100,dtype=torch.float64)\n",
        "    dsample = []\n",
        "    dsample.append(float(X['train']['gender'][0]))\n",
        "    dsample.extend(binary_representaiton(X['train']['color'][0],5))\n",
        "    dsample.extend(binary_representaiton(X['train']['sleeve'][0],3))\n",
        "    dsample.extend(binary_representaiton(X['train']['cate_new'][0],5))\n",
        "    dsample.append(X['train']['r'][0])\n",
        "    dsample.append(X['train']['g'][0])\n",
        "    dsample.append(X['train']['b'][0])\n",
        "    dsample.append(X['train']['y'][0])\n",
        "    dsample.extend(X['train']['encoding'][0])\n",
        "    dsample = np.array(dsample)\n",
        "    dsample = torch.from_numpy(dsample)\n",
        "    dzsample = torch.cat([dsample,zsample] , dim=0)\n",
        "    dzsample = dzsample.view((1,dzsample.shape[0],1,1))\n",
        "    dzsample = Variable(dzsample).to(device,dtype=torch.float)\n",
        "    mS0_sample = X['train']['down_sampled_images'][0]\n",
        "    mS0_sample = mS0_sample.view((1,4,8,8))\n",
        "    mS0_sample = Variable(mS0_sample).to(device,dtype=torch.float)\n",
        "    S_tilde_sample = G1.forward(dzsample,mS0_sample)\n",
        "    \n",
        "\n",
        "\n",
        "plt.plot(range(num_epochs), discriminator_loss)\n",
        "plt.show()\n",
        "plt.plot(range(num_epochs), generator_loss)\n",
        "plt.show()\n",
        "\n",
        "S_tilde_sample = S_tilde_sample.data.cpu().numpy()\n",
        "S_0_sample = X['train']['segmented_image'][0]\n",
        "\n",
        "S_tilde_sample =  S_tilde_sample.reshape(7,128,128)\n",
        "S_0_sample =S_0_sample.reshape(7,128,128)\n",
        "fig, ax = plt.subplots(nrows=7, ncols=2)#,figsize=(30,30)))\n",
        "for row_index, row in enumerate(ax,0):\n",
        "    row[0].imshow(S_tilde_sample[row_index])\n",
        "    row[1].imshow(S_0_sample[row_index])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I pickle\n",
            "Using device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:330: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0: discriminator_loss = 2.23300, generator_loss = 28.10676\n",
            "Training epoch 1: discriminator_loss = 2.16745, generator_loss = 13.68390\n",
            "Training epoch 2: discriminator_loss = 2.13967, generator_loss = 12.59032\n",
            "Training epoch 3: discriminator_loss = 2.11802, generator_loss = 12.14444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wywt2OF8eM4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(G1.state_dict(), '/content/drive/My Drive/G1.pth')\n",
        "torch.save(D1.state_dict(), '/content/drive/My Drive/D1.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGvXe_bivGPq",
        "colab_type": "text"
      },
      "source": [
        "Training loop of GAN 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acWuluMxr498",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G2 = Generator2()\n",
        "D2 = Discriminator2()\n",
        "if cuda:\n",
        "    G2.cuda()\n",
        "    D2.cuda()\n",
        "\n",
        "loss_pix = torch.nn.L1Loss()\n",
        "loss_GAN2 = torch.nn.BCELoss()\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "generator_2_optim = torch.optim.Adam(G2.parameters(), 0.0002, betas=(0.5, 0.999))\n",
        "discriminator_2_optim = torch.optim.Adam(D2.parameters(), 0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "discriminator_2_loss, generator_2_loss = [], []\n",
        "\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    batch_d_loss, batch_g_loss = [], []\n",
        "    \n",
        "    for i , data in enumerate(train_loader, 0):\n",
        "        #need: I0:original image\n",
        "        d, mS0, S0, label = data\n",
        "        \n",
        "        true_label = torch.ones(batch_size, 1,1,1).to(device)\n",
        "        fake_label = torch.zeros(batch_size, 1,1,1).to(device)\n",
        "        \n",
        "        D2.zero_grad()\n",
        "        \n",
        "\n",
        "        \n",
        "        \n",
        "        #################### Update D #############################\n",
        "        # loss 1. real image + real condition -> 1\n",
        "        x_true_S0 = Variable(S0).to(device,dtype=torch.float)\n",
        "        x_true_I0 = Variable(label).to(device,dtype=torch.float)\n",
        "        x_true_d = Variable(d).to(device,dtype=torch.float)        \n",
        "        output = D2.forward(x_true_d,x_true_I0,x_true_S0)\n",
        "        \n",
        "        error_true = loss_GAN2(output, true_label) \n",
        "        error_true.backward()\n",
        "\n",
        "        # loss 2. sampled real image + wrong condition -> 0\n",
        "        # shuffle d     \n",
        "        # shuffle the true d row wise\n",
        "        x_notmatch_d = x_true_d[torch.randperm(x_true_d.size()[0])]\n",
        "        \n",
        "        x_notmatch_d = Variable(x_notmatch_d).to(device)    \n",
        "        output = D2.forward(x_notmatch_d ,x_true_I0,x_true_S0)\n",
        "\n",
        "        error_notmatch = 0.2*loss_GAN2(output, fake_label) \n",
        "        error_notmatch.backward()\n",
        "\n",
        "        # loss 3. generated fake image + real condition -> 0s\n",
        "        # z = torch.randn(batch_size, 100, 1, 1,dtype=torch.float64)\n",
        "        z = torch.randn(batch_size, 100,dtype=torch.float64)\n",
        "        dz = torch.cat([d, z] , dim=1)\n",
        "        dz = dz.view((batch_size,dz.shape[1],1,1))\n",
        "        dz = Variable(dz).to(device,dtype=torch.float)\n",
        "        x_g_S0 = Variable(S0).to(device,dtype=torch.float)\n",
        "        \n",
        "        I_tilde = G2.forward(dz,x_g_S0)\n",
        "\n",
        "        x_fake_I = I_tilde\n",
        "        # x_fake_S = Variable(S_tilde).to(device)\n",
        "        x_fake_d = Variable(d).to(device,dtype=torch.float) \n",
        "        output = D2.forward(x_fake_d.detach(),x_fake_I.detach(),x_g_S0.detach())\n",
        "        \n",
        "\n",
        "        error_fake = 0.8*loss_GAN2(output, fake_label)#log(1-log(g(z)))\n",
        "        error_fake.backward()\n",
        "        discriminator_2_optim.step()\n",
        "\n",
        "            \n",
        "        G2.zero_grad()\n",
        "        \n",
        "        #################### Update G #############################\n",
        "        \n",
        "        \n",
        "        # Step 4. Send fake data through discriminator _again_\n",
        "        #         propagate the error of the generator and\n",
        "        #         update G weights.\n",
        "        output = D2.forward(x_fake_d,x_fake_I,x_g_S0)\n",
        "        target = Variable(label).to(device,dtype=torch.float)\n",
        "        error_D = loss_GAN2(output, true_label)\n",
        "        # error_D.backward()\n",
        "        error_seg = 50*loss_pix(x_fake_I,target)\n",
        "        # error_seg.backward\n",
        "        error_2_generator = error_seg + error_D\n",
        "        error_2_generator.backward()\n",
        "        generator_2_optim.step()\n",
        "        \n",
        "        # batch_d_loss.append((error_true/(error_true + error_fake + error_notmatch)).item())\n",
        "        batch_d_loss.append((error_true + error_fake + error_notmatch).item())\n",
        "        batch_g_loss.append(error_2_generator.item())\n",
        "\n",
        "    discriminator_2_loss.append(np.mean(batch_d_loss))\n",
        "    generator_2_loss.append(np.mean(batch_g_loss))\n",
        "\n",
        "    print('Training epoch %d: discriminator_2_loss = %.5f, generator_2_loss = %.5f' % (epoch, discriminator_2_loss[epoch].item(), generator_2_loss[epoch].item()))\n",
        "\n",
        "\n",
        "    # Generate data\n",
        "torch.save(G2.state_dict(), '/content/drive/My Drive/G2.pth')\n",
        "torch.save(D2.state_dict(), '/content/drive/My Drive/D2.pth')\n",
        "with torch.no_grad():\n",
        "    zsample = torch.randn(100,dtype=torch.float64)\n",
        "    dsample = []\n",
        "    dsample.append(float(X['train']['gender'][0]))\n",
        "    dsample.extend(binary_representaiton(X['train']['color'][0],5))\n",
        "    dsample.extend(binary_representaiton(X['train']['sleeve'][0],3))\n",
        "    dsample.extend(binary_representaiton(X['train']['cate_new'][0],5))\n",
        "    dsample.append(X['train']['r'][0])\n",
        "    dsample.append(X['train']['g'][0])\n",
        "    dsample.append(X['train']['b'][0])\n",
        "    dsample.append(X['train']['y'][0])\n",
        "    dsample.extend(X['train']['encoding'][0])\n",
        "    dsample = np.array(dsample)\n",
        "    dsample = torch.from_numpy(dsample)\n",
        "    dzsample = torch.cat([dsample,zsample] , dim=0)\n",
        "    dzsample = dzsample.view((1,dzsample.shape[0],1,1))\n",
        "    dzsample = Variable(dzsample).to(device,dtype=torch.float)\n",
        "    S0_sample = X['train']['segmented_image'][0]\n",
        "    S0_sample = S0_sample.view((1,7,128,128))\n",
        "    S0_sample = Variable(S0_sample).to(device,dtype=torch.float)\n",
        "    I_tilde_sample = G2.forward(dzsample,S0_sample)\n",
        "    \n",
        "\n",
        "\n",
        "plt.plot(range(num_epochs), discriminator_2_loss)\n",
        "plt.show()\n",
        "plt.plot(range(num_epochs), generator_2_loss)\n",
        "plt.show()\n",
        "\n",
        "I_tilde_sample = I_tilde_sample.data.cpu().numpy()\n",
        "I_tilde_sample =  I_tilde_sample.reshape(128,128,3)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(221)\n",
        "#ax.imshow((I_tilde_sample * 255).astype('uint8'))\n",
        "ax.imshow(I_tilde_sample)\n",
        "\n",
        "\n",
        "I_0_sample = label[0].data.cpu().numpy()\n",
        "I_0_sample =I_0_sample.reshape(128,128,3)\n",
        "ax = fig.add_subplot(222)\n",
        "ax.imshow(I_0_sample[1])\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXWmLE_6Fwni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PretrainedG1 = Generator1().to(device,dtype=torch.float)\n",
        "PretrainedG1.load_state_dict(torch.load('/content/drive/My Drive/G1.pth'))\n",
        "# PretrainedG2 = Generator2()\n",
        "# PretrainedG2.load_state_dict(torch.load('../../G2.pth'))\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
        "\n",
        "# load the data if you haven't\n",
        "# X, y = None,None\n",
        "\n",
        "# loaded_data = None\n",
        "# # if os.path.isfile(os.path.join(os.path.dirname(__file__),'..','data','debug_data_10k.pkl')):\n",
        "# #     with open(os.path.join(os.path.dirname(__file__),'..','data','debug_data_10k.pkl'),'rb') as handle:\n",
        "\n",
        "# if True:\n",
        "#     with open(\"/content/drive/My Drive/debug_data_10k.pkl\",'rb') as handle:\n",
        "#         print(\"I pickle\")\n",
        "#         loaded_data = pickle.load(handle)\n",
        "#         X,y = loaded_data[0],loaded_data[1]\n",
        "# else:\n",
        "#     # X, y = load_data()\n",
        "#     print(\"we don't have data in the drive\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    zsample = torch.randn(100,dtype=torch.float64)\n",
        "    dsample = []\n",
        "    dsample.append(float(X['train']['gender'][0]))\n",
        "    dsample.extend(binary_representaiton(X['train']['color'][0],5))\n",
        "    dsample.extend(binary_representaiton(X['train']['sleeve'][0],3))\n",
        "    dsample.extend(binary_representaiton(X['train']['cate_new'][0],5))\n",
        "    dsample.append(X['train']['r'][0])\n",
        "    dsample.append(X['train']['g'][0])\n",
        "    dsample.append(X['train']['b'][0])\n",
        "    dsample.append(X['train']['y'][0])\n",
        "    dsample.extend(X['train']['encoding'][0])\n",
        "    dsample = np.array(dsample)\n",
        "    dsample = torch.from_numpy(dsample)\n",
        "    dzsample = torch.cat([dsample,zsample] , dim=0)\n",
        "    dzsample = dzsample.view((1,dzsample.shape[0],1,1))\n",
        "    dzsample = Variable(dzsample).to(device,dtype=torch.float)\n",
        "    mS0_sample = X['train']['down_sampled_images'][0]\n",
        "    mS0_sample = mS0_sample.view((1,4,8,8))\n",
        "    mS0_sample = Variable(mS0_sample).to(device,dtype=torch.float)\n",
        "    S_tilde_sample = PretrainedG1.forward(dzsample,mS0_sample)\n",
        "    \n",
        "\n",
        "S_tilde_sample = S_tilde_sample.data.cpu().numpy()\n",
        "S_0_sample = X['train']['segmented_image'][0]\n",
        "\n",
        "S_tilde_sample =  S_tilde_sample.reshape(7,128,128)\n",
        "S_0_sample =S_0_sample.reshape(7,128,128)\n",
        "# fig, ax = plt.subplots(nrows=7, ncols=2)#,figsize=(30,30)))\n",
        "# for row_index, row in enumerate(ax,0):\n",
        "#     row[0].imshow(S_tilde_sample[row_index])\n",
        "#     row[1].imshow(S_0_sample[row_index])\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "for i in  range(len(S_tilde_sample)):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "    ax[0].imshow(S_tilde_sample[i])\n",
        "    ax[0].set_title(\"Generated\")\n",
        "    ax[1].imshow(S_0_sample[i])\n",
        "    ax[1].set_title(\"Original\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}